{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CXR Classifier for COVID-19 --- 2. Training the Modfied VGG16 Model\n",
    "\n",
    "This is a script to train or fine-tune a modified VGG16 model. This script allows you to load and train a modified VGG16 model. Once finished, the accuracy and loss function of the model on the training and validation data are plotted. The trained model is saved for later use.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Install packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages setup\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential, load_model \n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import itertools\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Load the modfied model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the modified model\n",
    "# 'modified_models/model_tf.h5' for transfer learning\n",
    "# 'modified_models/model_dl.h5' for traditional (deep) learning \n",
    "train_model = load_model('modified_models/model_tl.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the model you loaded is correct\n",
    "# for transfer learning, only the parameters from the final layers are trainable (i.e., 8194 )\n",
    "# for traditional learning, all parameters are trainable (i.e., 134,268,748)\n",
    "train_model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Load training data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data (the processed images) from the respective directories\n",
    "train_path = 'model_3/data_pro/train_pro'\n",
    "valid_path = 'model_3/data_pro/valid_pro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create batches of train, valid and test sets\n",
    "# batch_size = no. of images drawn to the model per iteration\n",
    "# all batches of images will be passed through the model after each epoch\n",
    "train_batches = ImageDataGenerator().flow_from_directory(train_path, target_size = (224,224), classes= ['covid', 'non-covid'], batch_size = 10)\n",
    "valid_batches = ImageDataGenerator().flow_from_directory(valid_path, target_size = (224,224), classes= ['covid', 'non-covid'], batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plot to plot images with their respective labels \n",
    "def plots(ims, figsize = (12,6), rows = 1, interp = False, titles = None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.tranpose((0,2,3,1))\n",
    "    f = plt.figure(figsize = figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize = 16)\n",
    "        plt.imshow(ims[i], interpolation = None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a batch of training data \n",
    "# plot that batch of training data with their respective labels\n",
    "imgs, labels = next(train_batches)\n",
    "plots(imgs, titles = labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Compiled and trained the modified model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# the optimizer is Adam, with the learning rate at 0.0001\n",
    "# the loss used is cross entropy loss\n",
    "train_model.compile(optimizer = Adam(learning_rate = 0.0001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call GPU\n",
    "# specify the GPU no. you want to use\n",
    "CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data to train\n",
    "# the no. of epoch is 50 by default\n",
    "# the verbosity is 2 (super-verbose) by default\n",
    "# details of training are stored in a variable called history\n",
    "history = train_model.fit(x = train_batches, validation_data = valid_batches, epochs = 50, verbose = 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. Plot the training accuracy and loss function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy against epochs\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and validation loss vs epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss Fucntion')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the weights changed after training if needed\n",
    "# omit unless necessary\n",
    "# model.get_weights()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__6. Save the trained model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the fine-tuned model after training\n",
    "# the architecture, weights, training configuration will be saved\n",
    "if os.path.isfile('model_3/save_model/model_3_new.h5') is False:\n",
    "    train_model.save('model_3/save_model/model_3_new.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
