{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CXR Classifier for COVID-19 --- 1. Modifying the VGG16 Model\n",
    "\n",
    "This is a script to modify a pre-trained VGG16 model. \n",
    "\n",
    "This script allows you to load a pre-trained VGG16 model from tensorflow.keras, build a sequential model from it. The final classification layer of the model is changed from a 1000-unit classifier to a 2-unit classifier to cater the need of this task (i.e., COVID-19 diagnosis or classification)\n",
    "\n",
    "If transfer learning is adopted, the weights of all layers before the final layer are freezed, so that they are not re-trained during fine-tuning. In other words, parameters within these layers are frozen and non-trainable. \n",
    "\n",
    "If traditional learning (i.e., deep learning) is adopted, all weights across all layers of the model can be retrained. All parameters remain trainable. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified models\n",
    "\n",
    "There are two modfiied VGG16 models available for usage. \n",
    "\n",
    "__'modified_models/model_tl.h5'__ is for transfer learning where all parameters before the final classification layer are frozen and non-trainable.\n",
    "\n",
    "\n",
    "__'modified_models/model_dl.h5'__ is for deep learning of the entire model wherea all parameters across the model can be re-trained. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Install packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages setup\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential \n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import itertools\n",
    "\n",
    "import os.path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Load the pre-trained model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the VGG16 model from tensorflow.keras\n",
    "vgg16_model = tf.keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the architecture of VGG16\n",
    "# VGG16 should have 23 layers\n",
    "# VGG16 should have a total of 138,357,544 parameters, which are all trainable\n",
    "# VGG16 should be able to predict 1000 classes\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the type of models of which VGG16 belongs to\n",
    "type(vgg16_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Modify the pre-trained model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform VGG16 from a Model to a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# create an input layer as it may be removed when the VGG16 model was loaded into a Sequential Model\n",
    "input_shape = (224, 224, 3)\n",
    "input_layer = Input(shape = input_shape)\n",
    "model.add(input_layer)\n",
    "\n",
    "# # loop through every layer of VGG16 (except for the last layer) and add that to the newly created Sequential model\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)\n",
    "\n",
    "\n",
    "# check that all layers of VGG16 were created in the Sequential model\n",
    "# the no. of layers and parameters should be consistent between the VGG16 Model and VGG16 Sequential model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the input shape is correct\n",
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers \n",
    "# the weights of these layers will remain unchanged during fine-tuning\n",
    "# omit this step if the model is retrained from scratch\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# check the new architecture\n",
    "# all trainable parameters should become non-trainable \n",
    "# the no. of trainable parameter should be 0\n",
    "# the no. of trainable parameter should be 134,260,544\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new Dense layer as the final layer \n",
    "# the Dense layer only classify data into 2 classes\n",
    "# Softmax is used as the activation function\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "# check the new architecture\n",
    "# the outptut shape of the last layer should be (None, 2)\n",
    "# the no. of trainable parameters should update from 0 to 8,194, which are all from the last layer\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Save the modified model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the modified after training\n",
    "# the architecture, weights, training configuration will be saved\n",
    "import os.path\n",
    "if os.path.isfile('modified_models/model_dl.h5') is False:\n",
    "    model.save('modified_models/model_dl.h5')\n",
    "\n",
    "# two models are modified and stored in modifed_models\n",
    "# modified_models/model_tl.h5 <--- all parameters before the final layer are non-trainable\n",
    "# modified_models/model_dl.h5 <--- all parameters across the model are trainable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "co",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
